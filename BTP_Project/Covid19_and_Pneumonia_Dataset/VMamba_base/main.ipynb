{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb05d98c-2ae5-49ed-ad11-f611bf88265c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import json\n",
    "import pickle\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import cv2\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets.folder import default_loader\n",
    "from torchvision.utils import make_grid, save_image\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, label_binarize\n",
    "from tqdm import tqdm\n",
    "import timm\n",
    "\n",
    "# from mamba_vision import mamba_vision_T as create_model\n",
    "from prediction_saver import PredictionArraySaver\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "268e2a97-48b5-415e-9b45-dc8edc74ad58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Config\n",
    "# -----------------------------\n",
    "BATCH_SIZE = 32\n",
    "NUM_WORKERS = 4\n",
    "EPOCHS = 100\n",
    "LR = 1e-4\n",
    "PATIENCE = 10\n",
    "MAX_MISCLASSIFIED_TO_SAVE = 20\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "RESULTS_DIR = Path(\"results\")\n",
    "RESULTS_DIR.mkdir(exist_ok=True)\n",
    "NEW_RESULTS_DIR = Path(\"final_results\")\n",
    "NEW_RESULTS_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# Update model list as needed (timm model names)\n",
    "MODEL_NAMES = [\n",
    "#    \"mobilevit_s\",\n",
    "#    \"mobilenetv3_small_100\",\n",
    "#    \"mobilenetv3_large_100\",\n",
    "#    \"tf_efficientnet_b0\",\n",
    "#    \"densenet201\",\n",
    "#    \"inception_v3\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4572f9a6-74ba-4de3-b6ff-5f917da7daa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Dataset class\n",
    "# -----------------------------\n",
    "class XrayDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.transform = transform\n",
    "        self.loader = default_loader\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.df.iloc[idx]['image_path']\n",
    "        label = int(self.df.iloc[idx]['label_encoded'])\n",
    "        image = self.loader(img_path).convert(\"RGB\")\n",
    "    \n",
    "        if self.transform:\n",
    "            view1 = self.transform(image)\n",
    "            view2 = self.transform(image)\n",
    "            return (view1, view2), label\n",
    "        else:\n",
    "            return (image, image), label\n",
    "\n",
    "               \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0c12864-ec46-4903-939b-3c3892799ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Grad-CAM\n",
    "# -----------------------------\n",
    "class GradCAM:\n",
    "    def __init__(self, model, target_layer):\n",
    "        self.model = model\n",
    "        self.target_layer = target_layer\n",
    "        self.gradients = None\n",
    "        self.activations = None\n",
    "        self.hook_handles = []\n",
    "        self._register_hooks()\n",
    "\n",
    "    def _register_hooks(self):\n",
    "        def forward_hook(module, inp, out):\n",
    "            self.activations = out.detach()\n",
    "        def backward_hook(module, grad_in, grad_out):\n",
    "            self.gradients = grad_out[0].detach()\n",
    "        self.hook_handles.append(self.target_layer.register_forward_hook(forward_hook))\n",
    "        self.hook_handles.append(self.target_layer.register_backward_hook(backward_hook))\n",
    "\n",
    "    def generate(self, input_tensor, target_class):\n",
    "        self.model.zero_grad()\n",
    "        output = self.model(input_tensor)\n",
    "        loss = output[:, target_class].sum()\n",
    "        loss.backward(retain_graph=True)\n",
    "        grads = self.gradients\n",
    "        acts = self.activations\n",
    "        weights = grads.mean(dim=(2,3), keepdim=True)\n",
    "        cam = (weights * acts).sum(dim=1, keepdim=True)\n",
    "        cam = torch.relu(cam)\n",
    "        cam = cam.squeeze().cpu().numpy()\n",
    "        cam = (cam - cam.min())/(cam.max()-cam.min()+1e-8)\n",
    "        return cam\n",
    "\n",
    "    def remove_hooks(self):\n",
    "        for h in self.hook_handles:\n",
    "            h.remove()\n",
    "\n",
    "def overlay_gradcam(img_pil, mask):\n",
    "    img = np.array(img_pil.resize((224, 224))).astype(np.uint8)\n",
    "\n",
    "    # Normalize mask\n",
    "    mask = cv2.resize(mask, (img.shape[1], img.shape[0]))\n",
    "    mask = (mask - mask.min()) / (mask.max() - mask.min() + 1e-8)  # normalize 0-1\n",
    "    mask = np.uint8(255 * mask)\n",
    "\n",
    "    # Apply colormap (makes it 3-channel)\n",
    "    heatmap = cv2.applyColorMap(mask, cv2.COLORMAP_JET)\n",
    "    heatmap = cv2.cvtColor(heatmap, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Ensure both are same shape & dtype\n",
    "    if heatmap.shape != img.shape:\n",
    "        heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n",
    "\n",
    "    overlay = cv2.addWeighted(img, 0.5, heatmap, 0.5, 0)\n",
    "\n",
    "    orig = Image.fromarray(img)\n",
    "    overlay = Image.fromarray(overlay)\n",
    "    return orig, overlay\n",
    "\n",
    "\n",
    "def generate_and_save_gradcam_samples(model, test_df, all_labels, all_preds, save_dir, classes, max_correct=20, max_misclassified=20):\n",
    "    gradcam_dir = save_dir / \"gradcam_samples\"\n",
    "    gradcam_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    model.eval()\n",
    "    #target_layer = model.backbone.features[-1]\n",
    "    target_layer = model.fu4\t\n",
    "\n",
    "    cam = GradCAM(model, target_layer)\n",
    "\n",
    "    mis_idx = np.where(np.array(all_labels)!=np.array(all_preds))[0]\n",
    "    cor_idx = np.where(np.array(all_labels)==np.array(all_preds))[0]\n",
    "    sel_idx = []\n",
    "    if len(mis_idx)>0:\n",
    "        sel_idx.extend(np.random.choice(mis_idx, min(max_misclassified,len(mis_idx)), replace=False))\n",
    "    if len(cor_idx)>0:\n",
    "        sel_idx.extend(np.random.choice(cor_idx, min(max_correct,len(cor_idx)), replace=False))\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224,224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
    "    ])\n",
    "    \n",
    "    indices = list(range(len(test_df)))\n",
    "    \n",
    "    for i in indices:\n",
    "        row = test_df.iloc[i]\n",
    "        img_pil = Image.open(row['image_path']).convert(\"RGB\").resize((224,224))\n",
    "        tensor = transform(img_pil).unsqueeze(0).to(DEVICE)\n",
    "        pred_class = all_preds[i]\n",
    "        true_class = all_labels[i]\n",
    "        mask = cam.generate(tensor, pred_class)\n",
    "        orig, overlay = overlay_gradcam(img_pil, mask)\n",
    "        # side by side\n",
    "        combined = np.hstack([orig, overlay])\n",
    "        combined_pil = Image.fromarray(combined)\n",
    "        draw = ImageDraw.Draw(combined_pil)\n",
    "        text = f\"True: {classes[true_class]} | Pred: {classes[pred_class]}\"\n",
    "        try:\n",
    "            font = ImageFont.truetype(\"arial.ttf\", 18)\n",
    "        except:\n",
    "            font = ImageFont.load_default()\n",
    "        draw.text((5,5), text, fill=(255,0,0), font=font)\n",
    "        out_path = gradcam_dir / f\"{i:04d}_T-{true_class}_P-{pred_class}.png\"\n",
    "        combined_pil.save(out_path)\n",
    "    cam.remove_hooks()\n",
    "    print(f\"‚úÖ Saved Grad-CAM samples to {gradcam_dir}\")\n",
    "\t\n",
    "    '''for count,i in enumerate(sel_idx):\n",
    "        row = test_df.iloc[i]\n",
    "        img_pil = Image.open(row['image_path']).convert(\"RGB\").resize((224,224))\n",
    "        tensor = transform(img_pil).unsqueeze(0).to(DEVICE)\n",
    "        pred_class = all_preds[i]\n",
    "        true_class = all_labels[i]\n",
    "        mask = cam.generate(tensor, pred_class)\n",
    "        orig, overlay = overlay_gradcam(img_pil, mask)\n",
    "        # side by side\n",
    "        combined = np.hstack([orig, overlay])\n",
    "        combined_pil = Image.fromarray(combined)\n",
    "        draw = ImageDraw.Draw(combined_pil)\n",
    "        text = f\"True: {classes[true_class]} | Pred: {classes[pred_class]}\"\n",
    "        try:\n",
    "            font = ImageFont.truetype(\"arial.ttf\", 18)\n",
    "        except:\n",
    "            font = ImageFont.load_default()\n",
    "        draw.text((5,5), text, fill=(255,0,0), font=font)\n",
    "        out_path = gradcam_dir / f\"{count:04d}_T-{classes[true_class]}_P-{classes[pred_class]}.png\"\n",
    "        combined_pil.save(out_path)\n",
    "    cam.remove_hooks()\n",
    "    print(f\"‚úÖ Saved Grad-CAM samples to {gradcam_dir}\")'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e8d7cf0-9838-482c-99d8-af25e58afe45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Utility functions\n",
    "# -----------------------------\n",
    "def print_class_distribution(df, split_name):\n",
    "    counter = Counter(df['label'])\n",
    "    print(f\"üìä {split_name} split distribution (total {len(df)}):\")\n",
    "    for cls, count in counter.items():\n",
    "        print(f\"   {cls}: {count}\")\n",
    "    print()\n",
    "\n",
    "def save_classification_report_text(report_text, path):\n",
    "    with open(path, \"w\") as f:\n",
    "        f.write(report_text)\n",
    "\n",
    "def save_metrics_json(metrics: dict, path):\n",
    "    with open(path, \"w\") as f:\n",
    "        json.dump(metrics, f, indent=2)\n",
    "\n",
    "def plot_and_save_confusion_matrix(cm, classes, path):\n",
    "    plt.figure(figsize=(6,5))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=classes, yticklabels=classes)\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(path)\n",
    "    plt.close()\n",
    "\n",
    "def plot_and_save_prediction_distribution(preds, classes, path):\n",
    "    counts = pd.Series(preds).value_counts().sort_index()\n",
    "    # ensure all classes are present in plot\n",
    "    counts = counts.reindex(range(len(classes)), fill_value=0)\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.bar(classes, counts.values)\n",
    "    plt.title(\"Predicted Class Distribution\")\n",
    "    plt.xlabel(\"Class\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(path)\n",
    "    plt.close()\n",
    "\n",
    "def plot_and_save_loss_accuracy(history, save_dir):\n",
    "    # loss\n",
    "    plt.figure(figsize=(8,5))\n",
    "    plt.plot(history['train_loss'], label='Train Loss')\n",
    "    plt.plot(history['val_loss'], label='Val Loss')\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Loss Curve\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_dir / \"loss_curve.png\")\n",
    "    plt.close()\n",
    "\n",
    "    # accuracy (val acc)\n",
    "    if 'val_acc' in history:\n",
    "        plt.figure(figsize=(8,5))\n",
    "        plt.plot(history['val_acc'], label='Val Accuracy')\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"Accuracy\")\n",
    "        plt.title(\"Validation Accuracy\")\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(save_dir / \"accuracy_curve.png\")\n",
    "        plt.close()\n",
    "\n",
    "def save_misclassified_samples(test_df, all_labels, all_preds, save_path, classes, max_samples=20, img_size=(224,224)):\n",
    "\n",
    "    all_labels = np.array(all_labels)\n",
    "    all_preds = np.array(all_preds)\n",
    "\n",
    "    mis_idx = np.where(all_labels != all_preds)[0]\n",
    "    correct_idx = np.where(all_labels == all_preds)[0]\n",
    "\n",
    "    selected_idx = []\n",
    "    if len(mis_idx) > 0:\n",
    "        selected_idx.extend(np.random.choice(mis_idx, size=min(max_samples//2, len(mis_idx)), replace=False))\n",
    "    if len(correct_idx) > 0:\n",
    "        selected_idx.extend(np.random.choice(correct_idx, size=min(max_samples//2, len(correct_idx)), replace=False))\n",
    "\n",
    "    if not selected_idx:\n",
    "        print(\"‚ö†Ô∏è No samples to display.\")\n",
    "        return\n",
    "\n",
    "    tensors = []\n",
    "    for i in selected_idx:\n",
    "        img_path = test_df.iloc[i]['image_path']\n",
    "        true_lbl = classes[all_labels[i]]\n",
    "        pred_lbl = classes[all_preds[i]]\n",
    "\n",
    "        img = default_loader(img_path).convert(\"RGB\")\n",
    "        img = img.resize(img_size)\n",
    "\n",
    "        # add text (True | Pred)\n",
    "        img_pil = img.copy()\n",
    "        draw = ImageDraw.Draw(img_pil)\n",
    "        try:\n",
    "            font = ImageFont.truetype(\"arial.ttf\", 16)\n",
    "        except:\n",
    "            font = ImageFont.load_default()\n",
    "        text = f\"T: {true_lbl} | P: {pred_lbl}\"\n",
    "        draw.text((5, 5), text, fill=(255, 0, 0), font=font)\n",
    "\n",
    "        tensor = transforms.ToTensor()(img_pil)  # normalized 0..1\n",
    "        tensors.append(tensor)\n",
    "\n",
    "    grid = make_grid(tensors, nrow=5, normalize=True)\n",
    "    save_image(grid, save_path)\n",
    "    print(f\"‚úÖ Saved samples(misclassified+correct) to {save_path}\")\n",
    "\n",
    "def plot_and_save_roc(all_labels, all_probs, classes, save_path):\n",
    "    num_classes = len(classes)\n",
    "    if num_classes == 2:\n",
    "        # binary\n",
    "        fpr, tpr, _ = roc_curve(all_labels, np.array(all_probs)[:, 1])\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        plt.figure(figsize=(6,6))\n",
    "        plt.plot(fpr, tpr, label=f\"ROC (AUC = {roc_auc:.2f})\")\n",
    "        plt.plot([0,1],[0,1],'k--', lw=2)\n",
    "        plt.xlabel(\"False Positive Rate\")\n",
    "        plt.ylabel(\"True Positive Rate\")\n",
    "        plt.title(\"ROC Curve\")\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(save_path)\n",
    "        plt.close()\n",
    "        return {\"binary_auc\": float(roc_auc)}\n",
    "    else:\n",
    "        y_true_bin = label_binarize(all_labels, classes=list(range(num_classes)))\n",
    "        probs_np = np.array(all_probs)\n",
    "        fpr = dict(); tpr = dict(); roc_auc = dict()\n",
    "        for i in range(num_classes):\n",
    "            try:\n",
    "                fpr[i], tpr[i], _ = roc_curve(y_true_bin[:, i], probs_np[:, i])\n",
    "                roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "            except ValueError:\n",
    "                fpr[i], tpr[i], roc_auc[i] = None, None, None\n",
    "\n",
    "        # micro-average\n",
    "        try:\n",
    "            fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_true_bin.ravel(), probs_np.ravel())\n",
    "            roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "        except ValueError:\n",
    "            fpr[\"micro\"], tpr[\"micro\"], roc_auc[\"micro\"] = None, None, None\n",
    "\n",
    "        plt.figure(figsize=(8,6))\n",
    "        if roc_auc[\"micro\"] is not None:\n",
    "            plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
    "                     label=f\"micro-average (AUC = {roc_auc['micro']:.2f})\",\n",
    "                     color=\"deeppink\", linestyle=\":\", linewidth=4)\n",
    "        colors = [\"blue\", \"green\", \"orange\", \"purple\", \"cyan\"]\n",
    "        for i, color in zip(range(num_classes), colors):\n",
    "            if fpr[i] is None:\n",
    "                continue\n",
    "            plt.plot(fpr[i], tpr[i], color=color, lw=2, label=f\"{classes[i]} (AUC = {roc_auc[i]:.2f})\")\n",
    "        plt.plot([0,1],[0,1],'k--', lw=2)\n",
    "        plt.xlim([0.0,1.0])\n",
    "        plt.ylim([0.0,1.05])\n",
    "        plt.xlabel(\"False Positive Rate\")\n",
    "        plt.ylabel(\"True Positive Rate\")\n",
    "        plt.title(\"Multi-class ROC\")\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(save_path)\n",
    "        plt.close()\n",
    "\n",
    "        # return per class aucs and micro\n",
    "        aucs = { (classes[i] if i in roc_auc else str(i)) : (float(roc_auc[i]) if roc_auc[i] is not None else None)\n",
    "                 for i in range(num_classes) }\n",
    "        aucs[\"micro\"] = float(roc_auc[\"micro\"]) if roc_auc[\"micro\"] is not None else None\n",
    "        return aucs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "affe1605-a162-48bd-9b29-02f571f09424",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "# -----------------------------\n",
    "# Loss function\n",
    "# -----------------------------\n",
    "class ContrastiveLoss(nn.Module):\n",
    "    def __init__(self, temperature=0.5):\n",
    "        super().__init__()\n",
    "        self.temperature = temperature\n",
    "        self.cosine = nn.CosineSimilarity(dim=-1)\n",
    "\n",
    "    def forward(self, z_i, z_j):\n",
    "        # z_i, z_j: embeddings of two augmented views of the same batch\n",
    "        batch_size = z_i.size(0)\n",
    "\n",
    "        # Normalize\n",
    "        z_i = F.normalize(z_i, dim=-1)\n",
    "        z_j = F.normalize(z_j, dim=-1)\n",
    "\n",
    "        # Similarity matrix\n",
    "        representations = torch.cat([z_i, z_j], dim=0)       # (2N, D)\n",
    "        sim_matrix = F.cosine_similarity(\n",
    "            representations.unsqueeze(1), \n",
    "            representations.unsqueeze(0), \n",
    "            dim=-1\n",
    "        ) / self.temperature\n",
    "\n",
    "        # Mask to remove self-similarity\n",
    "        mask = torch.eye(2*batch_size, device=z_i.device).bool()\n",
    "        sim_matrix = sim_matrix.masked_fill(mask, -9e15)\n",
    "\n",
    "        # Positive pairs: i-th sample in z_i with i-th sample in z_j\n",
    "        positives = torch.cat([torch.arange(batch_size, 2*batch_size),\n",
    "                               torch.arange(0, batch_size)]).to(z_i.device)\n",
    "\n",
    "        loss = F.cross_entropy(sim_matrix, positives)\n",
    "        return loss\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Training & evaluation\n",
    "# -----------------------------\n",
    "def train_and_eval_model(model_name, train_loader, val_loader, test_loader, train_df, val_df, test_df, num_classes, classes):\n",
    "    print(f\"\\n=== ‚ñ∂ Starting training for model: {model_name} ===\")\n",
    "    save_dir = RESULTS_DIR / model_name\n",
    "    save_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # create model\n",
    "    '''try:\n",
    "        model = timm.create_model(model_name, pretrained=True, num_classes=num_classes)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to create model {model_name} with pretrained weights: {e}\")\n",
    "        print(\"Trying without pretrained weights...\")\n",
    "        model = timm.create_model(model_name, pretrained=False, num_classes=num_classes)\n",
    "    model = model.to(DEVICE)'''\n",
    "    \n",
    "    model = create_model(num_classes=num_classes).to(DEVICE)\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.2, patience=3, min_lr=1e-6)\n",
    "\n",
    "    best_val_loss = float(\"inf\")\n",
    "    patience_counter = 0\n",
    "\n",
    "    history = {\"train_loss\": [], \"val_loss\": [], \"val_acc\": []}\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    contrastive_loss = ContrastiveLoss(temperature=0.5)\n",
    "    lambda_contrastive = 0.1\n",
    "    use_contrastive = False\n",
    "\n",
    "    for epoch in range(1, EPOCHS+1):\n",
    "        # --- train epoch ---\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for (inputs, aug_inputs), labels in tqdm(train_loader, desc=f\"{model_name} Epoch {epoch}/{EPOCHS} [Train]\"):\n",
    "            inputs, aug_inputs, labels = inputs.to(DEVICE), aug_inputs.to(DEVICE), labels.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            cls_loss = criterion(outputs, labels)\n",
    "\n",
    "            if use_contrastive:\n",
    "                embeddings = model.forward_features(inputs)\n",
    "                aug_embeddings = model.forward_features(aug_inputs)\n",
    "                contr_loss = contrastive_loss(embeddings, aug_embeddings)\n",
    "                loss = cls_loss + lambda_contrastive * contr_loss\n",
    "            else:\n",
    "                loss = cls_loss\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "        epoch_train_loss = running_loss / len(train_loader.dataset)\n",
    "\n",
    "        # --- validate epoch ---\n",
    "        model.eval()\n",
    "        running_val_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for (inputs, aug_inputs), labels in tqdm(val_loader, desc=f\"{model_name} Epoch {epoch}/{EPOCHS} [Val]\"):\n",
    "                inputs, aug_inputs, labels = inputs.to(DEVICE), aug_inputs.to(DEVICE), labels.to(DEVICE)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                running_val_loss += loss.item() * inputs.size(0)\n",
    "                preds = torch.argmax(outputs, dim=1)\n",
    "                correct += (preds == labels).sum().item()\n",
    "                total += labels.size(0)\n",
    "        epoch_val_loss = running_val_loss / len(val_loader.dataset)\n",
    "        epoch_val_acc = correct / total if total > 0 else 0.0\n",
    "\n",
    "        history[\"train_loss\"].append(epoch_train_loss)\n",
    "        history[\"val_loss\"].append(epoch_val_loss)\n",
    "        history[\"val_acc\"].append(epoch_val_acc)\n",
    "\n",
    "        print(f\"[{model_name}] Epoch {epoch}/{EPOCHS} ‚Äî train_loss: {epoch_train_loss:.4f}, val_loss: {epoch_val_loss:.4f}, val_acc: {epoch_val_acc:.4f}\")\n",
    "\n",
    "        scheduler.step(epoch_val_loss)\n",
    "\n",
    "        # early stopping\n",
    "        if epoch_val_loss < best_val_loss:\n",
    "            best_val_loss = epoch_val_loss\n",
    "            torch.save(model.state_dict(), save_dir / \"best_model.pth\")\n",
    "            patience_counter = 0\n",
    "            print(f\"  ‚Ü≥ New best val loss: {best_val_loss:.4f} (model saved)\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= PATIENCE:\n",
    "                print(f\"  ‚èπ Early stopping triggered after {PATIENCE} epochs without improvement.\")\n",
    "                break\n",
    "\n",
    "    # save history\n",
    "    with open(save_dir / \"history.pkl\", \"wb\") as f:\n",
    "        pickle.dump(history, f)\n",
    "    plot_and_save_loss_accuracy(history, save_dir)\n",
    "\n",
    "    # --- Testing ---\n",
    "    print(f\"üîç Starting testing for {model_name}\")\n",
    "    model.load_state_dict(torch.load(save_dir / \"best_model.pth\", map_location=DEVICE))\n",
    "    model.eval()\n",
    "    save_dir = NEW_RESULTS_DIR / model_name\n",
    "    save_dir.mkdir(parents=True, exist_ok=True)\n",
    "    torch.save(model.state_dict(), save_dir / \"best_model.pth\")\n",
    "\n",
    "    all_labels, all_preds, all_probs = [], [], []\n",
    "    with torch.no_grad():\n",
    "        for (inputs, aug_inputs), labels in tqdm(test_loader, desc=f\"{model_name} [Test]\"):\n",
    "            inputs = inputs.to(DEVICE)\n",
    "            outputs = model(inputs)\n",
    "            probs = torch.softmax(outputs, dim=1)\n",
    "            preds = torch.argmax(probs, dim=1)\n",
    "\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "\n",
    "    all_labels = np.array(all_labels)\n",
    "    all_preds = np.array(all_preds)\n",
    "    all_probs = np.array(all_probs)\n",
    "\n",
    "    # confusion matrix & classification report\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    clf_report_text = classification_report(all_labels, all_preds, target_names=classes)\n",
    "    clf_report_dict = classification_report(all_labels, all_preds, target_names=classes, output_dict=True)\n",
    "\n",
    "    # ROC & AUC\n",
    "    if num_classes == 2:\n",
    "        aucs = plot_and_save_roc(all_labels, all_probs, classes, save_dir / \"roc_curve.png\")\n",
    "        macro_auc = aucs.get(\"binary_auc\", None)\n",
    "        micro_auc = macro_auc\n",
    "        per_class_auc = {classes[1]: float(macro_auc)} if macro_auc is not None else {}\n",
    "    else:\n",
    "        per_class_auc = plot_and_save_roc(all_labels, all_probs, classes, save_dir / \"roc_curve.png\")\n",
    "        micro_auc = per_class_auc.get(\"micro\", None)\n",
    "        macro_auc = np.nanmean([v for k,v in per_class_auc.items() if k != \"micro\" and v is not None]) if per_class_auc else None\n",
    "\n",
    "    # save confusion matrix\n",
    "    plot_and_save_confusion_matrix(cm, classes, save_dir / \"confusion_matrix.png\")\n",
    "\n",
    "    # save prediction distribution\n",
    "    plot_and_save_prediction_distribution(all_preds, classes, save_dir / \"prediction_distribution.png\")\n",
    "\n",
    "    # save misclassified samples\n",
    "    save_misclassified_samples(\n",
    "        test_df.reset_index(drop=True),\n",
    "        all_labels,\n",
    "        all_preds,\n",
    "        save_dir / \"samples.png\",\n",
    "        classes,\n",
    "        max_samples=MAX_MISCLASSIFIED_TO_SAVE\n",
    "    )\n",
    "\n",
    "    # save classification report and metrics\n",
    "    with open(save_dir / \"classification_report.txt\", \"w\") as f:\n",
    "        f.write(clf_report_text)\n",
    "\n",
    "    metrics = {\n",
    "        \"classification_report\": clf_report_dict,\n",
    "        \"per_class_auc\": per_class_auc,\n",
    "        \"macro_auc\": float(macro_auc) if macro_auc is not None and not np.isnan(macro_auc) else None,\n",
    "        \"micro_auc\": float(micro_auc) if micro_auc is not None and not np.isnan(micro_auc) else None,\n",
    "        \"confusion_matrix\": cm.tolist()\n",
    "    }\n",
    "    save_metrics_json(metrics, save_dir / \"metrics.json\")\n",
    "\n",
    "    saver = PredictionArraySaver(save_dir)\n",
    "    saver.save_predictions(all_labels, all_preds, all_probs, classes, model_name)\n",
    "\n",
    "    print(f\"üìä Testing complete for {model_name}, results saved in {save_dir}\")\n",
    "    print(\"-----------------------------------------------------------\")\n",
    "    \n",
    "    # print(\"Running gradcam\")\n",
    "    # generate_and_save_gradcam_samples(model, test_df, all_labels, all_preds, save_dir, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ef223b44-2818-4181-abb8-42e483b940d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî¢ Label mapping: {'COVID': np.int64(0), 'NORMAL': np.int64(1), 'PNEUMONIA': np.int64(2)}\n",
      "üìå Number of classes: 3\n",
  
      "   COVID: 325\n",
      "\n",
      "\n",
      "=== ‚ñ∂ Starting training for model: mamba_vision_tiny ===\n",
      "üîç Starting testing for mamba_vision_tiny\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mamba_vision_tiny [Test]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 33/33 [00:01<00:00, 16.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved samples(misclassified+correct) to final_results/mamba_vision_tiny/samples.png\n",
      "\n",
      "======================================================================\n",
      "üíæ Saving prediction arrays for: mamba_vision_tiny\n",
      "======================================================================\n",
      "‚úÖ Saved raw arrays:\n",
      "   - all_labels.npy: shape (1046,)\n",
      "   - all_preds.npy: shape (1046,)\n",
      "   - all_probs.npy: shape (1046, 1000)\n",
      "‚úÖ Saved confusion_matrix.npy: shape (3, 3)\n",
      "‚úÖ Saved per_class_metrics.json and .npy\n",
      "‚úÖ Saved roc_data.json and .npy\n",
      "‚úÖ Saved pr_data.json and .npy\n",
      "‚úÖ Saved aggregate_metrics.json and .npy\n",
      "‚úÖ Saved metadata.json\n",
      "======================================================================\n",
      "\n",
      "üìä Testing complete for mamba_vision_tiny, results saved in final_results/mamba_vision_tiny\n",
      "-----------------------------------------------------------\n",
      "üèÅ All models processed!\n"
     ]
    }
   ],
   "source": [
    "    # -----------------------------\n",
    "    # Main\n",
    "    # -----------------------------\n",
    "    \n",
    "    train_df = pd.read_csv(\"train_dataset.csv\")\n",
    "    val_df = pd.read_csv(\"val_dataset.csv\")\n",
    "    test_df = pd.read_csv(\"test_dataset.csv\")\n",
    "\n",
    "    # Encode labels\n",
    "    le = LabelEncoder()\n",
    "    train_df['label_encoded'] = le.fit_transform(train_df['label'])\n",
    "    val_df['label_encoded'] = le.transform(val_df['label'])\n",
    "    test_df['label_encoded'] = le.transform(test_df['label'])\n",
    "    classes = list(le.classes_)\n",
    "    num_classes = len(classes)\n",
    "    print(\"üî¢ Label mapping:\", dict(zip(le.classes_, le.transform(le.classes_))))\n",
    "\n",
    "    # print summary\n",
    "    print(f\"üìå Number of classes: {num_classes}\")\n",
    "    print_class_distribution(train_df, \"Train\")\n",
    "    print_class_distribution(val_df, \"Validation\")\n",
    "    print_class_distribution(test_df, \"Test\")\n",
    "\n",
    "    # transforms\n",
    "    train_transform = transforms.Compose([\n",
    "    \ttransforms.Resize((224,224)),\n",
    "    \ttransforms.RandomHorizontalFlip(p=0.5),                # HF\n",
    "       \ttransforms.RandomRotation(degrees=15),                 # ROT\n",
    "    \ttransforms.ToTensor(),\n",
    "    \ttransforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
    "    ])\n",
    "    test_transform = transforms.Compose([\n",
    "        transforms.Resize((224,224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
    "    ])\n",
    "\n",
    "    # datasets and loaders\n",
    "    train_dataset = XrayDataset(train_df, transform=train_transform)\n",
    "    val_dataset = XrayDataset(val_df, transform=test_transform)\n",
    "    test_dataset = XrayDataset(test_df, transform=test_transform)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
    "\n",
    "    # loop models\n",
    "    '''for model_name in MODEL_NAMES:\n",
    "        train_and_eval_model(model_name, train_loader, val_loader, test_loader, train_df, val_df, test_df, num_classes, classes)'''\n",
    "\n",
    "    # from MedMamba import get_medmamba_s as create_model\n",
    "    # train_and_eval_model(\"MedMamba_small\", train_loader, val_loader, test_loader, train_df, val_df, test_df, num_classes, classes)\n",
    "\n",
    "    # from MedMamba import get_medmamba_t as create_model\n",
    "    # train_and_eval_model(\"MedMamba_tiny\", train_loader, val_loader, test_loader, train_df, val_df, test_df, num_classes, classes)\n",
    "\n",
    "    # from MedMamba import get_medmamba_b as create_model\n",
    "    # train_and_eval_model(\"MedMamba_base\", train_loader, val_loader, test_loader, train_df, val_df, test_df, num_classes, classes)\n",
    "\n",
    "    # from mamba_vision import mamba_vision_T as create_model\n",
    "    # train_and_eval_model(\"mamba_vision_tiny\", train_loader, val_loader, test_loader, train_df, val_df, test_df, num_classes, classes)\n",
    "\n",
    "    # from mamba_vision import mamba_vision_B as create_model\n",
    "    # train_and_eval_model(\"mamba_vision_base\", train_loader, val_loader, test_loader, train_df, val_df, test_df, num_classes, classes)\n",
    "\n",
    "    # from mamba_vision import mamba_vision_S as create_model\n",
    "    # train_and_eval_model(\"mamba_vision_small\", train_loader, val_loader, test_loader, train_df, val_df, test_df, num_classes, classes)\n",
    "\n",
    "    # from hifuse_model import HiFuse_Tiny as create_model\n",
    "    # train_and_eval_model(\"HiFuse_Tiny\", train_loader, val_loader, test_loader, train_df, val_df, test_df, num_classes, classes)\n",
    "\n",
    "    # from hifuse_model import HiFuse_Base as create_model\n",
    "    # train_and_eval_model(\"HiFuse_Base\", train_loader, val_loader, test_loader, train_df, val_df, test_df, num_classes, classes)\n",
    "\n",
    "    # from hifuse_model import HiFuse_Small as create_model\n",
    "    # train_and_eval_model(\"HiFuse_Small\", train_loader, val_loader, test_loader, train_df, val_df, test_df, num_classes, classes)\n",
    "\n",
    "    from VMamba.vmamba import vanilla_vmamba_small as create_model\n",
    "    train_and_eval_model(\"VMamba_small\", train_loader, val_loader, test_loader, train_df, val_df, test_df, num_classes, classes)\n",
    "\n",
    "    from VMamba.vmamba import vanilla_vmamba_tiny as create_model\n",
    "    train_and_eval_model(\"VMamba_tiny\", train_loader, val_loader, test_loader, train_df, val_df, test_df, num_classes, classes)\n",
    "\n",
    "    from VMamba.vmamba import vanilla_vmamba_base as create_model\n",
    "    train_and_eval_model(\"VMamba_base\", train_loader, val_loader, test_loader, train_df, val_df, test_df, num_classes, classes)\n",
    "\n",
    "    print(\"üèÅ All models processed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297de561-220d-4b96-a567-0683074c993e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
